{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "folder `dataset` i `predictions` powinny byc w tym samym katalogu, z ktorego sie uruchamia"
      ],
      "metadata": {
        "id": "eZqoFRHgaW0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import kagglehub\n",
        "\n",
        "# #ustaw na swoja\n",
        "# path = kagglehub.dataset_download(\"ipythonx/mvtec-ad\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "-qGV73krzKyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /root/.cache/kagglehub/datasets/ipythonx/mvtec-ad/versions/2 /content/dataset"
      ],
      "metadata": {
        "id": "U3Lzuaxm0QGT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1tUCxIRPwcn"
      },
      "outputs": [],
      "source": [
        "# !pip install anomalib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "atrhmJGBPz-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8679df1-c6fc-4379-af79-b7d558b96332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import gc\n",
        "import os\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PPi2mXZWQON",
        "outputId": "d00fe775-618c-43ba-e8d8-5310b9ff0119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bottle\t carpet    leather\tpill\t    tile\twood\n",
            "cable\t grid\t   license.txt\treadme.txt  toothbrush\tzipper\n",
            "capsule  hazelnut  metal_nut\tscrew\t    transistor\n"
          ]
        }
      ],
      "source": [
        "!ls dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "h89ZSS5pt5t5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K7tndqbzWvlN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def dataset_generator(root_path, go_to_test=True):\n",
        "    \"\"\"\n",
        "    Generator iterujÄ…cy po obrazach w folderach 'test' w strukturze MVTec.\n",
        "\n",
        "    \"\"\"\n",
        "    dataset = Path(root_path)\n",
        "    valid_extensions = {'.png'}\n",
        "\n",
        "    # 1. Iterujemy po klasach (np. capsule, screw)\n",
        "    for class_dir in dataset.iterdir():\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "\n",
        "        if go_to_test:\n",
        "          test_dir = class_dir / 'test'\n",
        "          if not test_dir.exists():\n",
        "              continue\n",
        "\n",
        "        # 3. Iterujemy po typach defektÃ³w/good (to sÄ… nasze labele)\n",
        "        for label_dir in test_dir.iterdir():\n",
        "            if not label_dir.is_dir():\n",
        "                continue\n",
        "\n",
        "            label = label_dir.name\n",
        "\n",
        "            for image_path in label_dir.iterdir():\n",
        "                if image_path.suffix.lower() in valid_extensions:\n",
        "                    # Zwracamy absolutnÄ… Å›cieÅ¼kÄ™ jako string oraz label\n",
        "                    yield str(image_path.resolve()), label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "miÄ™sko"
      ],
      "metadata": {
        "id": "2vBvbFERt7SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dir = Path(\"predictions\")\n",
        "os.makedirs(preds_dir, exist_ok=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "lkaYWLGOz_28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e8beea-d6bf-4930-aafa-ff5f9c127386"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT2Bwy4yXF0U"
      },
      "outputs": [],
      "source": [
        "def run_llava_eval(question, data_provider, res_dir = preds_dir, res_file_prefix: str = None):\n",
        "  lava_model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
        "  lava_model = LlavaForConditionalGeneration.from_pretrained(\n",
        "      lava_model_id,\n",
        "      torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "      device_map=\"auto\" if device == \"cuda\" else None,\n",
        "      low_cpu_mem_usage=True\n",
        "  )\n",
        "  lava_processor = AutoProcessor.from_pretrained(lava_model_id)\n",
        "\n",
        "  lava_outputs = []\n",
        "\n",
        "  for i, (path, label) in enumerate(tqdm(dataset_generator('dataset_path'))):\n",
        "      image = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "      conversation = [\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\"type\": \"image\", \"image\": image},\n",
        "                  {\"type\": \"text\", \"text\": question}\n",
        "              ],\n",
        "          }\n",
        "      ]\n",
        "\n",
        "      inputs = lava_processor.apply_chat_template(\n",
        "          conversation,\n",
        "          add_generation_prompt=True,\n",
        "          tokenize=True,\n",
        "          return_dict=True,\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "      inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "      input_len = inputs[\"input_ids\"].shape[1]  # ðŸ”‘ KLUCZOWE\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output_ids = lava_model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=100,\n",
        "              do_sample=False\n",
        "          )\n",
        "\n",
        "      # âœ… WYCIÄ„GAMY TYLKO NOWO WYGENEROWANE TOKENY\n",
        "      answer_ids = output_ids[:, input_len:]\n",
        "\n",
        "      response = lava_processor.batch_decode(\n",
        "          answer_ids,\n",
        "          skip_special_tokens=True\n",
        "      )[0].strip()\n",
        "\n",
        "      lava_outputs.append({\n",
        "          \"image_path\": path,\n",
        "          \"lava_response\": response,\n",
        "          \"label\": label\n",
        "      })\n",
        "\n",
        "      # if i == 2: break\n",
        "\n",
        "  lava_results_file = f\"{res_file_prefix if res_file_prefix else \"\"}lava_outputs.json\"\n",
        "  with open(res_dir / lava_results_file, \"w\") as f:\n",
        "      json.dump(lava_outputs, f, indent=4)\n",
        "\n",
        "  print(f\"LLaVA outputs saved to {lava_results_file}\")\n",
        "\n",
        "  del lava_model, lava_processor\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return res_dir / lava_results_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZpD3PTmXUZR"
      },
      "outputs": [],
      "source": [
        "def run_qwen_eval(llava_eval_path, EXTENDED_TEST = False, res_dir = preds_dir, res_file_prefix: str = None):\n",
        "  with open(llava_eval_path, \"r\") as f:\n",
        "      lava_outputs = json.load(f)\n",
        "  print(f\"Loaded {len(lava_outputs)} LLaVA outputs for Qwen processing.\")\n",
        "\n",
        "  qwen_model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "  qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_name)\n",
        "  qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "      qwen_model_name,\n",
        "      device_map=\"auto\" if device == \"cuda\" else None,\n",
        "      torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "      low_cpu_mem_usage=True\n",
        "  )\n",
        "\n",
        "  qwen_results = []\n",
        "\n",
        "  for lava_out in tqdm(lava_outputs):\n",
        "      if not EXTENDED_TEST:\n",
        "        lava_out[\"label\"] = \"anomaly\" if lava_out[\"label\"] == \"good\" else \"normal\"\n",
        "        prompt = (\n",
        "            \"You are given a condition description of an inspected object.\\n\\n\"\n",
        "            \"Description:\\n\"\n",
        "            f\"{lava_out['lava_response']}\\n\\n\"\n",
        "            \"Question:\\n\"\n",
        "            \"Does the description indicate the presence of any defect or anomaly?\\n\\n\"\n",
        "            \"Answer 'yes' if an anomaly is indicated.\\n\"\n",
        "            \"Answer 'no' if the object appears normal and defect-free.\\n\"\n",
        "            \"Answer 'yes' or 'no' only, nothing else.\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "      else:\n",
        "        prompt = (\n",
        "            \"You are given a condition description of an inspected object.\\n\\n\"\n",
        "            \"Description:\\n\"\n",
        "            f\"{lava_out['lava_response'].replace(\"_\", \" \").capitalize()}.\\n\\n\"\n",
        "            \"Question:\\n\"\n",
        "            \"Does the description indicate the presence of any defect or anomaly?\\n\\n\"\n",
        "            \"Answer 'yes' if an anomaly is indicated.\\n\"\n",
        "            \"Answer 'no' if the object appears normal and defect-free.\\n\"\n",
        "            \"Answer 'yes' or 'no' only, nothing else.\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "\n",
        "      inputs = qwen_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "      input_len = inputs[\"input_ids\"].shape[1]  # ðŸ”‘ KLUCZOWE\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output_ids = qwen_model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=5,\n",
        "              do_sample=False\n",
        "          )\n",
        "\n",
        "      # TYLKO NOWE TOKENY (ODPOWIEDÅ¹)\n",
        "      answer_ids = output_ids[:, input_len:]\n",
        "      response = qwen_tokenizer.decode(\n",
        "          answer_ids[0],\n",
        "          skip_special_tokens=True\n",
        "      ).strip().lower()\n",
        "\n",
        "      expected = \"yes\" if lava_out[\"label\"] == \"anomaly\" else \"no\"\n",
        "\n",
        "      if response.startswith(expected):\n",
        "          prediction = \"matches_label\"\n",
        "      elif response.startswith(\"yes\") or response.startswith(\"no\"):\n",
        "          prediction = \"does_not_match_label\"\n",
        "      else:\n",
        "          prediction = \"unknown\"\n",
        "\n",
        "      qwen_results.append({\n",
        "          \"image_path\": lava_out[\"image_path\"],\n",
        "          \"lava_response\": lava_out[\"lava_response\"],\n",
        "          \"label\": lava_out[\"label\"],\n",
        "          \"qwen_answer\": response,\n",
        "          \"qwen_prediction\": prediction\n",
        "      })\n",
        "\n",
        "  # for res in qwen_results:\n",
        "  #     print(\"=== IMAGE ===\", res[\"image_path\"])\n",
        "  #     print(\"LLaVA Output:\", res[\"lava_response\"])\n",
        "  #     print(\"LABEL:\", res[\"label\"])\n",
        "  #     print(\"Qwen Answer:\", res[\"qwen_answer\"])\n",
        "  #     print(\"Parsed:\", res[\"qwen_prediction\"])\n",
        "  #     print(\"-----------------------------\")\n",
        "\n",
        "  qwen_results_file = f\"{res_file_prefix if res_file_prefix else \"\"}qwen_results{\"_extended\" if EXTENDED_TEST else \"\"}.json\"\n",
        "  with open(res_dir/ qwen_results_file, \"w\") as f:\n",
        "      json.dump(qwen_results, f, indent=4)\n",
        "\n",
        "  print(f\"Qwen results saved to {qwen_results_file}\")\n",
        "\n",
        "  del qwen_model, qwen_tokenizer\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return preds_dir / qwen_results_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STIYgcIsfkmk"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking score"
      ],
      "metadata": {
        "id": "KVlqRyNM7Xbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz-8LK82ftDw"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(qwen_results_path: str) -> float:\n",
        "    \"\"\"\n",
        "    Computes accuracy as the percentage of entries with\n",
        "    qwen_prediction == 'matches_label'.\n",
        "    \"\"\"\n",
        "    with open(qwen_results_path, \"r\") as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    if len(results) == 0:\n",
        "        print(\"No results found.\")\n",
        "        return 0.0\n",
        "\n",
        "    total = len(results)\n",
        "    correct = sum(\n",
        "        1 for r in results\n",
        "        if r.get(\"qwen_prediction\") == \"matches_label\"\n",
        "    )\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run experiments"
      ],
      "metadata": {
        "id": "t9dYdIf77Z0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dwa typy runow:\n",
        "\n",
        "- **Zwykly test** poleg na potwirdzeniu przez qwen czy llava zauwazym czy jest jakakolwiek anomalia.\n",
        "\n",
        "- **Extended test** rozszerza to o dodatkowe sprawdzenie czy rodzaj anmoalii sie zgadza; rodzaj jest brany z labela (np. dla pill to beda color, combined, crack, ...)"
      ],
      "metadata": {
        "id": "R9EYyWLzWXXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, on a raw dataset test samples:"
      ],
      "metadata": {
        "id": "xkqkH1HD7fei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = (\n",
        "      \"Inspect the object for defects like scratches, cracks, fractures, \"\n",
        "      \"bending, or any other visible defects. \"\n",
        "      \"If found, describe the anomaly .\"\n",
        "      \"Otherwise, provide a neutral description. \"\n",
        "  )\n",
        "llava_res_path = run_llava_eval(question, dataset_generator('dataset', go_to_test=True))"
      ],
      "metadata": {
        "id": "Dln7BKD77kLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qwen_res_path = run_qwen_eval(llava_eval_path = llava_res_path, EXTENDED_TEST = False)\n",
        "qwen_res_path_extended = run_qwen_eval(llava_eval_path = llava_res_path, EXTENDED_TEST = True)"
      ],
      "metadata": {
        "id": "cw8fiv0Q7tGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zwykly"
      ],
      "metadata": {
        "id": "6a5VB032XWeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(qwen_res_path)"
      ],
      "metadata": {
        "id": "I8ax98HK8H1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extended"
      ],
      "metadata": {
        "id": "eFaogiC4XX2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(qwen_res_path_extended)"
      ],
      "metadata": {
        "id": "XjGEPaRH8NEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now, on a WinCLIP anomaly prediciton regions:"
      ],
      "metadata": {
        "id": "SXt-Zl-L8eL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = (\n",
        "    \"Focusing your attention specifically on the areas enclosed within the two red bounding boxes, \"\n",
        "    \"inspect for defects like scratches, cracks, fractures, bending, or any other visible anomalies. \"\n",
        "    \"If a defect is found in these areas, describe it. \"\n",
        "    \"Otherwise, provide a neutral description indicating the area is clear.\"\n",
        ")\n",
        "llava_res_path = run_llava_eval(dataset_generator('predictions', go_to_test=False))"
      ],
      "metadata": {
        "id": "JmCT2ibp8d0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qwen_res_path = run_qwen_eval(llava_eval_path = llava_res_path, EXTENDED_TEST = False, res_file_prefix='winclip')\n",
        "qwen_res_path_extended = run_qwen_eval(llava_eval_path = llava_res_path, EXTENDED_TEST = True, res_file_prefix='winclip')"
      ],
      "metadata": {
        "id": "RZaUyMat8kON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zwykly"
      ],
      "metadata": {
        "id": "nxnDfHeWXZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(qwen_res_path)"
      ],
      "metadata": {
        "id": "RWdzRhcF8lGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extgended"
      ],
      "metadata": {
        "id": "aqeNv-q4XaxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(qwen_res_path_extended)"
      ],
      "metadata": {
        "id": "kSmVUniB8l4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dhe_ZhJmBDdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mozna jeszcze wyekstrachowac staty dla psozczegolncyh klas"
      ],
      "metadata": {
        "id": "HZs-tvVfXdDx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clK8rGO7Xgc5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}